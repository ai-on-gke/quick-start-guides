# Copyright 2024 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

steps:
- id: "validate platform"
  name: "hashicorp/terraform:latest"
  dir: "/workspace/common/infrastructure/"
  waitFor: ["-"]
  script: |
    terraform init -no-color
    terraform validate -no-color

- id: "validate ray"
  name: "hashicorp/terraform:latest"
  dir: "/workspace/ray-on-gke/"
  waitFor: ["validate platform"]
  script: |
    terraform init -no-color
    terraform validate -no-color

- id: "validate jupyterhub"
  name: "hashicorp/terraform:latest"
  dir: "/workspace/jupyter/"
  waitFor: ["validate platform"]
  script: |
    terraform init -no-color
    terraform validate -no-color

- id: "validate rag"
  name: "hashicorp/terraform:latest"
  dir: "/workspace/rag/"
  waitFor: ["validate platform"]
  script: |
    terraform init -no-color
    terraform validate -no-color

- id: 'create gke cluster'
  name: "hashicorp/terraform:latest"
  env:
  - "KUBE_LOAD_CONFIG_FILE=false"
  dir: "/workspace/common/infrastructure/"
  allowFailure: true
  waitFor: ["validate platform", "validate ray", "validate jupyterhub", "validate rag"]
  entrypoint: 'sh'
  args:
  - '-c'
  - |
    set -e

    echo "create gke cluster"
    # terraform apply \
    # -var-file=tfvars_tests/standard-gke-public.platform.tfvars \
    # -var=project_id=$PROJECT_ID \
    # -var=network_name=ml-$SHORT_SHA-$_PR_NUMBER-$_BUILD_ID-$_AUTOPILOT_CLUSTER  \
    # -var=subnetwork_name=ml-$SHORT_SHA-$_PR_NUMBER-$_BUILD_ID-$_AUTOPILOT_CLUSTER  \
    # -var=subnetwork_region=$_REGION \
    # -var=cluster_name=ml-$SHORT_SHA-$_PR_NUMBER-$_BUILD_ID-cluster \
    # -var=autopilot_cluster=$_AUTOPILOT_CLUSTER \
    # -var=cluster_location=$_REGION \
    # -var='cpu_pools=[{initial_node_count=2,name="cpu-pool",machine_type="n1-standard-16",autoscaling=true,min_count=1,max_count=3,disk_size_gb=100,disk_type="pd-standard",}]' \
    # -var='gpu_pools=[{initial_node_count=2,name="gpu-pool",machine_type="g2-standard-24",autoscaling=true,min_count=1,max_count=3,disk_size_gb=100,disk_type="pd-balanced",accelerator_count=2,accelerator_type="nvidia-l4",gpu_driver_version="DEFAULT",}]' \
    # -auto-approve -no-color
    echo "pass" > /workspace/gke_cluster_result.txt

- id: 'Generate Kubeconfig'
  name: 'gcr.io/cloud-builders/gcloud'
  args:
  - 'container'
  - 'clusters'
  - 'get-credentials'
  # - 'ml-${SHORT_SHA}-${_PR_NUMBER}-${_BUILD_ID}-cluster'
  - 'ml-373a855--7e5eca7e-cluster'
  # - '--region=${_REGION}'
  - '--region=us-east4'
  - '--project=$PROJECT_ID'
  allowFailure: true
  waitFor: ['create gke cluster']

- id: "Test kubectl"
  name: "gcr.io/cloud-builders/kubectl"
  env:
    - "CLOUDSDK_COMPUTE_ZONE=${_REGION}"
    - "CLOUDSDK_CONTAINER_CLUSTER=ml-373a855--7e5eca7e-cluster"
  args:
    - "get"
    - "nodes"

- id: 'test ray cluster'
  name: "hashicorp/terraform:latest"
  allowFailure: true
  waitFor: ['create gke cluster']
  entrypoint: 'sh'
  args:
  - '-c'
  - |
    set -e

    cd /workspace/ray-on-gke/
    kubectl get nodes

# - id: 'test ray cluster'
#   name: 'gcr.io/$PROJECT_ID/terraform'
#   allowFailure: true
#   waitFor: ['create gke cluster']
#   entrypoint: 'sh'
#   args:
#   - '-c'
#   - |
#     set -e

#     cd /workspace/ray-on-gke/
#     terraform apply \
#     -var-file=workloads.tfvars \
#     -var=project_id=$PROJECT_ID \
#     # -var=cluster_name=ml-$SHORT_SHA-$_PR_NUMBER-$_BUILD_ID-cluster \
#     -var=cluster_name=ml-373a855--7e5eca7e-cluster \
#     -var=cluster_location=$_REGION \
#     -var=kubernetes_namespace=ml-$SHORT_SHA-$_BUILD_ID-ray \
#     -var=workload_identity_service_account=ray-sa-$SHORT_SHA-$_BUILD_ID \
#     -var=gcs_bucket=gke-aieco-ray-$SHORT_SHA-$_BUILD_ID \
#     -var=enable_gpu=true \
#     -auto-approve -no-color
#     echo "pass" > /workspace/user_result.txt

#     chmod +x /workspace/scripts/ci/wait_for_pods.sh
#     /workspace/scripts/ci/wait_for_pods.sh ml-$SHORT_SHA-$_BUILD_ID-ray 3000

#     kubectl wait --all pods -n ml-$SHORT_SHA-$_BUILD_ID-ray --for=condition=Ready --timeout=1200s
#     # Ray head's readinessProbe is not probing the head service today. Therefore the wait for ready above is not reliable.
#     sleep 60s
#     kubectl port-forward -n ml-$SHORT_SHA-$_BUILD_ID-ray service/ray-cluster-kuberay-head-svc 8265:8265 &
#     # Wait port-forwarding to take its place
#     sleep 10s

#     ray job submit \
#     --address=http://127.0.0.1:8265 -- python -c "import ray; ray.init(); print(ray.cluster_resources())"
#     echo "pass" > /workspace/ray_result.txt

# - id: 'cleanup ray cluster'
#   name: 'gcr.io/$PROJECT_ID/terraform'
#   entrypoint: 'bash'
#   args:
#   - '-c'
#   - |
#     set -e

#     cd /workspace/applications/ray/
#     terraform destroy \
#     -var-file=workloads.tfvars \
#     -var=project_id=$PROJECT_ID \
#     -var=cluster_name=ml-$SHORT_SHA-$_PR_NUMBER-$_BUILD_ID-cluster \
#     -var=cluster_location=$_REGION \
#     -var=kubernetes_namespace=ml-$SHORT_SHA-$_BUILD_ID-ray \
#     -var=workload_identity_service_account=ray-sa-$SHORT_SHA-$_BUILD_ID \
#     -var=gcs_bucket=gke-aieco-ray-$SHORT_SHA-$_BUILD_ID \
#     -var=enable_gpu=true \
#     -auto-approve -no-color
#   allowFailure: true
#   waitFor: ['test ray cluster']

# - id: 'test jupyterhub'
#   name: 'gcr.io/$PROJECT_ID/terraform'
#   entrypoint: 'bash'
#   args:
#   - '-c'
#   - |
#     set -e

#     cd /workspace/modules/jupyter/tests
#     python3 change_jupyter_config.py $_AUTOPILOT_CLUSTER

#     cd /workspace/applications/jupyter
#     terraform apply \
#     -var-file=workloads-without-iap.example.tfvars \
#     -var=project_id=$PROJECT_ID \
#     -var=cluster_name=ml-$SHORT_SHA-$_PR_NUMBER-$_BUILD_ID-cluster \
#     -var=cluster_location=$_REGION \
#     -var=kubernetes_namespace=ml-$SHORT_SHA-$_BUILD_ID-jupyter \
#     -var=workload_identity_service_account=jupyter-sa-$SHORT_SHA-$_BUILD_ID \
#     -var=gcs_bucket=gke-aieco-jupyter-$SHORT_SHA-$_BUILD_ID \
#     -auto-approve -no-color
#     echo "pass" > /workspace/jupyterhub_tf_result.txt

#     kubectl wait --for=condition=Ready pods -n ml-$SHORT_SHA-$_BUILD_ID-jupyter -l 'component!=continuous-image-puller' --timeout=1800s
#     kubectl get services -n ml-$SHORT_SHA-$_BUILD_ID-jupyter
#     kubectl port-forward -n ml-$SHORT_SHA-$_BUILD_ID-jupyter service/proxy-public 9442:80 &
#     # Wait port-forwarding to take its place
#     sleep 5s

#     cd /workspace/modules/jupyter/tests
#     python3 test_hub.py "127.0.0.1:9442" $_AUTOPILOT_CLUSTER
#     echo "pass" > /workspace/jupyterhub_test_result.txt
#   allowFailure: true
#   waitFor: ['create gke cluster']

# - id: 'cleanup jupyterhub'
#   name: 'gcr.io/$PROJECT_ID/terraform'
#   entrypoint: 'bash'
#   args:
#   - '-c'
#   - |
#     set -e

#     cd /workspace/applications/jupyter/
#     terraform destroy \
#     -var-file=workloads-without-iap.example.tfvars \
#     -var=project_id=$PROJECT_ID \
#     -var=cluster_name=ml-$SHORT_SHA-$_PR_NUMBER-$_BUILD_ID-cluster \
#     -var=cluster_location=$_REGION \
#     -var=kubernetes_namespace=ml-$SHORT_SHA-$_BUILD_ID-jupyter \
#     -var=workload_identity_service_account=jupyter-sa-$SHORT_SHA-$_BUILD_ID \
#     -var=gcs_bucket=gke-aieco-jupyter-$SHORT_SHA-$_BUILD_ID \
#     -auto-approve -no-color
#   allowFailure: true
#   waitFor: ['test jupyterhub']

# - id: 'test rag'
#   name: 'gcr.io/$PROJECT_ID/terraform'
#   entrypoint: 'sh'
#   secretEnv: ['KAGGLE_USERNAME', 'KAGGLE_KEY']
#   args:
#   - '-c'
#   - |
#     set -e

#     # Get kube config
#     gcloud container clusters get-credentials \
#     ml-$SHORT_SHA-$_PR_NUMBER-$_BUILD_ID-cluster \
#     --location $_REGION \
#     --project $PROJECT_ID

#     cd /workspace/modules/jupyter/tests
#     python3 change_jupyter_config.py $_AUTOPILOT_CLUSTER

#     cd /workspace/applications/rag/
#     terraform apply \
#     -var-file=workloads.tfvars \
#     -var=network_name=ml-$SHORT_SHA-$_PR_NUMBER-$_BUILD_ID-$_AUTOPILOT_CLUSTER  \
#     -var=create_cluster=false \
#     -var=jupyter_add_auth=false \
#     -var=frontend_add_auth=false \
#     -var=project_id=$PROJECT_ID \
#     -var=cluster_name=ml-$SHORT_SHA-$_PR_NUMBER-$_BUILD_ID-cluster \
#     -var=cluster_location=$_REGION \
#     -var=kubernetes_namespace=rag-$SHORT_SHA-$_BUILD_ID \
#     -var=gcs_bucket=gke-aieco-rag-$SHORT_SHA-$_BUILD_ID \
#     -var=ray_service_account=ray-sa-4-rag-$SHORT_SHA-$_BUILD_ID \
#     -var=rag_service_account=rag-sa-4-rag-$SHORT_SHA-$_BUILD_ID \
#     -var=jupyter_service_account=jupyter-sa-4-rag-$SHORT_SHA-$_BUILD_ID \
#     -var=cloudsql_instance=pgvector-instance-$SHORT_SHA-$_BUILD_ID \
#     -auto-approve -no-color
#     echo "pass" > /workspace/rag_tf_result.txt

#     # Validate Ray: Make sure pods are running
#     kubectl wait --for=condition=Ready pods -n rag-$SHORT_SHA-$_BUILD_ID -l 'component!=continuous-image-puller' --timeout=1200s
#     kubectl port-forward -n rag-$SHORT_SHA-$_BUILD_ID service/ray-cluster-kuberay-head-svc 8262:8265 &
#     # Wait port-forwarding to take its place
#     sleep 5s

#     # Validate Ray: Check dashboard
#     ray job submit --working-dir ./tests \
#     --address=http://127.0.0.1:8262 -- python -c "import ray; ray.init(); print(ray.cluster_resources())"
#     echo "pass" > /workspace/rag_ray_dashboard_result.txt

#     # Validate JupyterHub: Get hub url
#     kubectl get services -n rag-$SHORT_SHA-$_BUILD_ID
#     kubectl port-forward -n rag-$SHORT_SHA-$_BUILD_ID service/proxy-public 9443:80 &
#     # Wait port-forwarding to take its place
#     sleep 5s

#     # Validate JupyterHub: Test Hub
#     cd /workspace/modules/jupyter/tests
#     python3 test_hub.py "127.0.0.1:9443" $_AUTOPILOT_CLUSTER
#     echo "pass" > /workspace/rag_jupyterhub_test_result.txt

#     # Validate RAG: Test rag frontend
#     kubectl port-forward -n rag-$SHORT_SHA-$_BUILD_ID service/rag-frontend 8081:8080 &
#     # Wait port-forwarding to take its place
#     sleep 5s

#     cd /workspace/applications/rag/tests
#     python3 test_frontend.py "127.0.0.1:8081"
#     echo "pass" > /workspace/rag_frontend_result.txt

#     cd /workspace/
#     sed -i "s/<username>/$$KAGGLE_USERNAME/g" ./applications/rag/example_notebooks/rag-kaggle-ray-sql-interactive.ipynb
#     sed -i "s/<token>/$$KAGGLE_KEY/g" ./applications/rag/example_notebooks/rag-kaggle-ray-sql-interactive.ipynb
#     gsutil cp ./applications/rag/example_notebooks/rag-kaggle-ray-sql-interactive.ipynb gs://gke-aieco-rag-$SHORT_SHA-$_BUILD_ID/
#     kubectl exec -it -n rag-$SHORT_SHA-$_BUILD_ID $(kubectl get pod -l app=jupyterhub,component=hub -n rag-$SHORT_SHA-$_BUILD_ID -o jsonpath="{.items[0].metadata.name}") -- jupyterhub token admin --log-level=CRITICAL | xargs python3 ./applications/rag/notebook_starter.py
#     # Wait for jupyterhub to trigger notebook pod startup
#     sleep 5s
#     kubectl wait --for=condition=Ready pod/jupyter-admin -n rag-$SHORT_SHA-$_BUILD_ID --timeout=500s
#     kubectl exec -it -n rag-$SHORT_SHA-$_BUILD_ID jupyter-admin -c notebook -- jupyter nbconvert --to script /data/rag-kaggle-ray-sql-interactive.ipynb
#     kubectl exec -it -n rag-$SHORT_SHA-$_BUILD_ID jupyter-admin -c notebook -- ipython /data/rag-kaggle-ray-sql-interactive.py

#     python3 ./applications/rag/tests/test_rag.py "http://127.0.0.1:8081/prompt"
#     echo "pass" > /workspace/rag_prompt_result.txt

#   allowFailure: true
#   waitFor: ['create gke cluster']

# - id: 'cleanup rag'
#   name: 'gcr.io/$PROJECT_ID/terraform'
#   entrypoint: 'bash'
#   args:
#   - '-c'
#   - |
#     set -e

#     cd /workspace/applications/rag/
#     terraform destroy \
#     -var-file=workloads.tfvars \
#     -var=network_name=ml-$SHORT_SHA-$_PR_NUMBER-$_BUILD_ID-$_AUTOPILOT_CLUSTER  \
#     -var=create_cluster=false \
#     -var=jupyter_add_auth=false \
#     -var=frontend_add_auth=false \
#     -var=project_id=$PROJECT_ID \
#     -var=cluster_name=ml-$SHORT_SHA-$_PR_NUMBER-$_BUILD_ID-cluster \
#     -var=cluster_location=$_REGION \
#     -var=kubernetes_namespace=rag-$SHORT_SHA-$_BUILD_ID \
#     -var=gcs_bucket=gke-aieco-rag-$SHORT_SHA-$_BUILD_ID \
#     -var=ray_service_account=ray-sa-$SHORT_SHA-$_BUILD_ID \
#     -var=rag_service_account=rag-sa-$SHORT_SHA-$_BUILD_ID \
#     -var=jupyter_service_account=jupyter-sa-$SHORT_SHA-$_BUILD_ID \
#     -var=cloudsql_instance=pgvector-instance-$SHORT_SHA-$_BUILD_ID \
#     -auto-approve -no-color
#   allowFailure: true
#   waitFor: ['test rag']

# - id: 'cleanup gke cluster'
#   # name: 'gcr.io/$PROJECT_ID/terraform'
#   name: "hashicorp/terraform:latest"
#   entrypoint: 'sh'
#   args:
#   - '-c'
#   - |
#     set -e

#     echo "cleanup gke cluster step!"
#     # terraform destroy -var-file=tfvars_tests/standard-gke-public.platform.tfvars -var=project_id=$PROJECT_ID \
#     # -var=cluster_name=ml-$SHORT_SHA-$_PR_NUMBER-$_BUILD_ID-cluster \
#     # -var=network_name=ml-$SHORT_SHA-$_PR_NUMBER-$_BUILD_ID-$_AUTOPILOT_CLUSTER  \
#     # -var=subnetwork_name=ml-$SHORT_SHA-$_PR_NUMBER-$_BUILD_ID-$_AUTOPILOT_CLUSTER  \
#     # -var=autopilot_cluster=$_AUTOPILOT_CLUSTER \
#     # -var=cluster_location=$_REGION -auto-approve -no-color

#   dir: "common/infrastructure/"
#   allowFailure: true
#   waitFor: ['cleanup rag']

# - id: 'check result'
#   # name: 'gcr.io/$PROJECT_ID/terraform'
#   name: "hashicorp/terraform:latest"
#   entrypoint: 'sh'
#   args:
#   - '-c'
#   - |
#     if [[ $(cat /workspace/gke_cluster_result.txt) != "pass" ]]; then
#       echo "gke cluster creation failed"
#       exit 1
#     fi

#     if [[ $(cat /workspace/rag_tf_result.txt) != "pass" ]]; then
#       echo "rag tf failed"
#       exit 1
#     fi

#     if [[ $(cat /workspace/rag_jupyterhub_test_result.txt) != "pass" ]]; then
#       echo "rag jupyterhub test failed"
#       exit 1
#     fi

#     if [[ $(cat /workspace/rag_frontend_result.txt) != "pass" ]]; then
#       echo "rag frontend test failed"
#       exit 1
#     fi

#     if [[ $(cat /workspace/rag_prompt_result.txt) != "pass" ]]; then
#       echo "rag prompt test failed"
#       exit 1
#     fi

#     if grep -q "Validation failed" /workspace/shipshape_on_cluster.txt; then
#       echo "Shipshape on cluster scan validation failed, please check the log. knowledge share slides: go/shipshape-ai-on-gke-slide"
#       exit 1
#     fi

#     if grep -q "Validation failed" /workspace/shipshape_on_helm.txt; then
#       echo "Shipshape on helm scan validation failed, please check the log. knowledge share slides: go/shipshape-ai-on-gke-slide"
#       exit 1
#     fi
  # waitFor: ['cleanup gke cluster']

substitutions:
  _REGION: us-east4
  _USER_NAME: github
  _AUTOPILOT_CLUSTER: "false"
  _BUILD_ID: ${BUILD_ID:0:8}
  _SHIPSHAPE_IMAGE: us-docker.pkg.dev/k8ssecurityvalidation-agent/k8ssecurityvalidation-agent/k8ssecurityvalidation-agent@sha256:cd45e6cd84e9a45462ddbca18c4731fd4e264d517ee98131eb5be4eb57691f44
logsBucket: gs://ai-on-gke-qss-build-logs
options:
  substitutionOption: "ALLOW_LOOSE"
  machineType: "E2_HIGHCPU_8"
timeout: 5400s
# availableSecrets:
#   secretManager:
#   - versionName: projects/ai-on-gke-qss/secrets/cloudbuild-kaggle-username/versions/latest
#     env: "KAGGLE_USERNAME"
#   - versionName: projects/ai-on-gke-qss/secrets/cloudbuild-kaggle-key/versions/latest
#     env: "KAGGLE_KEY"
